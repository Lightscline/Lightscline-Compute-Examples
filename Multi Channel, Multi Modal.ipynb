{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350ae508",
   "metadata": {},
   "source": [
    "\n",
    "### TLDR:\n",
    "1. Download and install the software.\n",
    "2. Import your data\n",
    "3. Train your model\n",
    "4. See the test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ef017",
   "metadata": {},
   "source": [
    "The following is an example on Human Activity Recognition use-case. Lightscline is always happy to help if you are stuck anywhere. Feel free to e-mail/text us anytime. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e93e5",
   "metadata": {},
   "source": [
    "## 1. Download and Install the software\n",
    "\n",
    "### 1.1 Download the software \n",
    "\n",
    "\n",
    "1. <a href=\"https://calendly.com/lightscline/lightscline-ai-demo\" target=\"_blank\">Book a meeting here </a>.\n",
    "2. Within 24 hrs of the meeting, You will get the link to download our software\n",
    "\n",
    "### 1.2 Install our software\n",
    "\n",
    "Our current software works with **python 3.9, 3.10 and 3.11** . Please let us know for any more version support.\n",
    "\n",
    "0. (optional) Create a virtual environment \n",
    "\n",
    " - run `python -m venv env` to create a new virtual environment. This should create a folder named env.\n",
    " - run `.\\env\\Scripts\\activate` to activate the virtual environment.\n",
    " - (optional) install jupyter notebook for iteractive session `pip install jupyter`\n",
    " \n",
    "1. Download and install Microsoft Visual C++ Redistributable: https://aka.ms/vs/16/release/vc_redist.x64.exe  \n",
    "2. Install lightscline package by `pip install <path to the .whl file>`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566c9bf",
   "metadata": {},
   "source": [
    "### 1.3 Import the package to check if it is correctly installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535b9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a pilot version with limited capabilities.\n",
      "Please contact us at info@lightscline.com for the full version. Our team will guide you through the complete suite of functionalities, tailored for your specific needs.\n",
      "License is valid till  20 November 2024\n"
     ]
    }
   ],
   "source": [
    "from lightscline.lightscline import LightsclineCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e0ddf",
   "metadata": {},
   "source": [
    "## 2. Import your data\n",
    "\n",
    "You can either import your data or use a dummy dataset to see how it work. \n",
    "\n",
    "Code for Dummy Data:\n",
    "```\n",
    "fs=[1200,1800]\n",
    "time_for_each_class=[10,16,18]\n",
    "\n",
    "no_of_classes = len(time_for_each_class)\n",
    "no_of_channels = len(fs)\n",
    "data = []\n",
    "for i in range(no_of_classes):\n",
    "    data_class = []\n",
    "    for j in range(no_of_channels):\n",
    "        data_channel = []\n",
    "        data_channel.append(float((i+1)*10+(j+1))+0.1)\n",
    "        data_channel*=int(fs[j]*time_for_each_class[i])\n",
    "        data_class.append(data_channel)\n",
    "    data.append(data_class)\n",
    "```\n",
    "\n",
    "This will create data with 3 classes with unequal data and each class would have 2 channels of data with different sampling frequencies. The following example is on <a href=\"https://archive.ics.uci.edu/dataset/231/pamap2+physical+activity+monitoring\" target=\"_blank\"> PAMAP2 Dataset </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee576960",
   "metadata": {},
   "source": [
    "### 2.1 Data Preparation for ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9591d-c430-4d66-b708-d77a2321968a",
   "metadata": {},
   "source": [
    "\n",
    "1. Download the dataset <a href=\"https://archive.ics.uci.edu/static/public/231/pamap2+physical+activity+monitoring.zip\" target=\"_blank\">here</a>\n",
    "\n",
    "2. Unzip the files\n",
    "\n",
    "Or Uncomment the below commands for the above two steps. \n",
    "\n",
    "You can also use your own dataset here instead of using the example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977cbaaf-081f-46dd-9f23-db2a44fe8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://archive.ics.uci.edu/static/public/231/pamap2+physical+activity+monitoring.zip\n",
    "# !tar -xf \"pamap2+physical+activity+monitoring.zip\"\n",
    "# !tar -xf \"PAMAP2_Dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35634b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f82868",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d738bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(r'<path>/PAMAP2_Dataset\\Protocol\\*')  \n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78edea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take data into all files into one dataframe\n",
    "df_temp = []\n",
    "for file in files:\n",
    "    t = pd.read_csv(file, header = None, delimiter=' ')\n",
    "    t.ffill(inplace=True) ##because sampling rate for each sensor maynot be same\n",
    "    df_temp.append(t)\n",
    "df = pd.concat(df_temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac21375",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data cleaning.\n",
    "df = df[df[1]!=0]\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80fc9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e66884f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_label = {labels[i]:i for i in range(len(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce6e4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### seperating data for each label. Note that we are keeping continous data of same class in one column. If same class has \n",
    "## disconuity\n",
    "breakpoints = df[df[1].shift() != df[1]].index \n",
    "label_data = []\n",
    "c_label = []\n",
    "for i in range(len(breakpoints)-1):\n",
    "    temp_df = df.iloc[breakpoints[i]:breakpoints[i+1]]\n",
    "    if (temp_df.shape[0])<1000:\n",
    "        continue  ##skip too small windows of data\n",
    "    assert(temp_df[1].nunique()==1) ## make sure only one class is present\n",
    "    label_data.append(temp_df.loc[:,3:].to_numpy().T.tolist())\n",
    "    t_c_label = temp_df[1].iloc[0]\n",
    "    c_label.append(reverse_label[t_c_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d002a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 104, array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_data), len(c_label), np.unique(c_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6325ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffcf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in label_data:\n",
    "    if len(i[0]) < 1000:\n",
    "        print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c211362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 51, 27187)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_data), len(label_data[0]), len(label_data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84efaf",
   "metadata": {},
   "source": [
    "### 2.3 Ingest your data into Lightscline Compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce446bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "License is valid till  20 November 2024\n"
     ]
    }
   ],
   "source": [
    "ls = LightsclineCompute(data=label_data,fs = 100,labels = c_label)  ## Labels will be decided based on column number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "667ab10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.reduce_and_preprocess_data(per_reduction=90, window_time=1, data_aug_multiplier=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4628adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 loss:  2.515644073486328\n",
      "epoch:  51 loss:  1.7156381607055664\n",
      "epoch:  101 loss:  1.3024115562438965\n",
      "epoch:  151 loss:  1.0106568336486816\n",
      "epoch:  201 loss:  0.8239051103591919\n",
      "epoch:  251 loss:  0.6998270153999329\n",
      "epoch:  301 loss:  0.6100802421569824\n",
      "epoch:  351 loss:  0.5407705903053284\n",
      "epoch:  401 loss:  0.4867238700389862\n",
      "epoch:  451 loss:  0.44622424244880676\n",
      "epoch:  501 loss:  0.4141707122325897\n",
      "epoch:  551 loss:  0.38581231236457825\n",
      "epoch:  601 loss:  0.3604455292224884\n",
      "epoch:  651 loss:  0.33924534916877747\n",
      "epoch:  701 loss:  0.32002148032188416\n",
      "epoch:  751 loss:  0.30491337180137634\n",
      "epoch:  801 loss:  0.2901945412158966\n",
      "epoch:  851 loss:  0.27855536341667175\n",
      "epoch:  901 loss:  0.2674615979194641\n",
      "epoch:  951 loss:  0.25677353143692017\n"
     ]
    }
   ],
   "source": [
    "ls.train_model(layers=(50,30),verbose=True,n_iters = 1000, learning_rate=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a73c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.93\n"
     ]
    }
   ],
   "source": [
    "ls.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fede58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [label_data[0][ch][:300] for ch in range(51)]\n",
    "ls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7c5644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for getting only one value, you can take out the \"Mode\" of predictions.\n",
    "import statistics\n",
    "statistics.mode(ls.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce09d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
